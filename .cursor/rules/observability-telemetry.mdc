---
description: Observability and Telemetry Combined Rules
globs:
alwaysApply: false
---
# Observability and Telemetry Combined Rules

This file contains rules for integrated observability and telemetry code generation. It guides the AI in generating code that combines observability practices with comprehensive telemetry collection for maximum system visibility and insights.

## Unified Observability and Telemetry Strategy

### Integration Philosophy
- Combine the three pillars of observability (metrics, logs, traces) with business telemetry
- Use telemetry to drive observability insights and vice versa
- Implement unified correlation across all data types
- Design for both operational monitoring and business analytics
- Enable closed-loop feedback between observability and telemetry systems

### Unified Data Model
- Standardize event schemas across observability and telemetry
- Use common correlation identifiers throughout the system
- Implement semantic conventions for consistency
- Enable cross-cutting analysis between operational and business metrics

## Integrated Event Collection Framework

### Unified Event Collector
```python
# Example: Integrated observability and telemetry collector
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List, Union
from datetime import datetime
import uuid
import json
import threading
import queue
import time
from abc import ABC, abstractmethod

@dataclass
class UnifiedEvent:
    """Unified event structure for both observability and telemetry"""
    # Core identification
    event_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    timestamp: datetime = field(default_factory=datetime.utcnow)

    # Event classification
    domain: str = ""  # 'observability' or 'telemetry' or 'business'
    category: str = ""  # 'metric', 'log', 'trace', 'user_interaction', 'system_event'
    type: str = ""  # Specific event type
    name: str = ""  # Event name

    # Data payload
    properties: Dict[str, Any] = field(default_factory=dict)
    measurements: Dict[str, float] = field(default_factory=dict)

    # Correlation and context
    trace_id: Optional[str] = None
    span_id: Optional[str] = None
    parent_span_id: Optional[str] = None
    correlation_id: Optional[str] = None
    session_id: Optional[str] = None
    user_id: Optional[str] = None

    # System context
    service_name: str = ""
    service_version: str = ""
    environment: str = "production"
    host_name: str = ""

    # Observability specific
    severity: Optional[str] = None  # For logs and alerts
    status: Optional[str] = None  # For traces and operations

    # Telemetry specific
    business_impact: Optional[str] = None
    user_segment: Optional[str] = None
    feature_flag: Optional[str] = None

    # Metadata
    tags: List[str] = field(default_factory=list)
    custom_dimensions: Dict[str, str] = field(default_factory=dict)

    def to_observability_format(self) -> Dict[str, Any]:
        """Convert to observability-focused format"""
        return {
            'timestamp': self.timestamp.isoformat(),
            'trace_id': self.trace_id,
            'span_id': self.span_id,
            'service_name': self.service_name,
            'event_name': self.name,
            'event_type': self.category,
            'severity': self.severity,
            'status': self.status,
            'properties': self.properties,
            'measurements': self.measurements,
            'tags': self.tags
        }

    def to_telemetry_format(self) -> Dict[str, Any]:
        """Convert to telemetry-focused format"""
        return {
            'event_id': self.event_id,
            'timestamp': self.timestamp.isoformat(),
            'event_type': self.type,
            'name': self.name,
            'user_id': self.user_id,
            'session_id': self.session_id,
            'business_impact': self.business_impact,
            'user_segment': self.user_segment,
            'feature_flag': self.feature_flag,
            'properties': self.properties,
            'measurements': self.measurements,
            'custom_dimensions': self.custom_dimensions
        }

    def to_unified_format(self) -> Dict[str, Any]:
        """Convert to unified format containing all fields"""
        return {
            'event_id': self.event_id,
            'timestamp': self.timestamp.isoformat(),
            'domain': self.domain,
            'category': self.category,
            'type': self.type,
            'name': self.name,
            'properties': self.properties,
            'measurements': self.measurements,
            'correlation': {
                'trace_id': self.trace_id,
                'span_id': self.span_id,
                'parent_span_id': self.parent_span_id,
                'correlation_id': self.correlation_id,
                'session_id': self.session_id,
                'user_id': self.user_id
            },
            'context': {
                'service_name': self.service_name,
                'service_version': self.service_version,
                'environment': self.environment,
                'host_name': self.host_name
            },
            'observability': {
                'severity': self.severity,
                'status': self.status
            },
            'telemetry': {
                'business_impact': self.business_impact,
                'user_segment': self.user_segment,
                'feature_flag': self.feature_flag
            },
            'metadata': {
                'tags': self.tags,
                'custom_dimensions': self.custom_dimensions
            }
        }

class UnifiedEventCollector:
    """Unified collector for observability and telemetry events"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.event_buffer = queue.Queue(maxsize=config.get('buffer_size', 10000))
        self.processors = {}
        self.exporters = {}
        self.running = False
        self.worker_thread = None

        # Context providers
        self.trace_context = None
        self.user_context = None
        self.feature_flags = None

        # Sampling and filtering
        self.sampling_rules = config.get('sampling_rules', {})
        self.filters = config.get('filters', [])

    def start(self):
        """Start the unified collector"""
        if not self.running:
            self.running = True
            self.worker_thread = threading.Thread(target=self._process_events)
            self.worker_thread.daemon = True
            self.worker_thread.start()

    def stop(self):
        """Stop the collector and flush remaining events"""
        self.running = False
        if self.worker_thread:
            self.worker_thread.join(timeout=5)
        self._flush_remaining_events()

    def collect_event(self, event: UnifiedEvent):
        """Collect a unified event"""
        try:
            # Enrich event with context
            enriched_event = self._enrich_event(event)

            # Apply sampling
            if not self._should_sample(enriched_event):
                return

            # Apply filters
            if not self._passes_filters(enriched_event):
                return

            # Add to buffer
            if not self.event_buffer.full():
                self.event_buffer.put(enriched_event, timeout=1)
            else:
                # Handle buffer overflow
                self._handle_buffer_overflow()

        except Exception as e:
            print(f"Error collecting event: {e}")

    def track_operation(self, operation_name: str, duration_ms: float,
                       success: bool = True, error_message: Optional[str] = None,
                       business_context: Optional[Dict] = None):
        """Track an operation with both observability and telemetry data"""
        event = UnifiedEvent(
            domain="observability",
            category="performance",
            type="operation",
            name=operation_name,
            measurements={'duration_ms': duration_ms},
            status='success' if success else 'error',
            severity='info' if success else 'error'
        )

        if error_message:
            event.properties['error_message'] = error_message

        if business_context:
            event.business_impact = business_context.get('impact')
            event.properties.update(business_context)

        self.collect_event(event)

    def track_user_interaction(self, action: str, target: str,
                             outcome: str = 'success',
                             duration_ms: Optional[float] = None,
                             feature_flag: Optional[str] = None):
        """Track user interaction with telemetry and observability context"""
        event = UnifiedEvent(
            domain="telemetry",
            category="user_interaction",
            type="user_action",
            name=f"user.{action}",
            properties={
                'action': action,
                'target': target,
                'outcome': outcome
            },
            feature_flag=feature_flag,
            business_impact='high' if action in ['purchase', 'signup'] else 'medium'
        )

        if duration_ms:
            event.measurements['duration_ms'] = duration_ms

        self.collect_event(event)

    def track_system_metric(self, metric_name: str, value: float,
                          metric_type: str = 'gauge',
                          tags: Optional[List[str]] = None):
        """Track system metric with observability context"""
        event = UnifiedEvent(
            domain="observability",
            category="metric",
            type=metric_type,
            name=metric_name,
            measurements={metric_name: value},
            tags=tags or []
        )

        self.collect_event(event)

    def track_business_event(self, event_name: str, impact: str,
                           revenue: Optional[float] = None,
                           user_segment: Optional[str] = None,
                           properties: Optional[Dict] = None):
        """Track business event with telemetry focus"""
        event = UnifiedEvent(
            domain="telemetry",
            category="business_event",
            type="business_metric",
            name=event_name,
            business_impact=impact,
            user_segment=user_segment,
            properties=properties or {}
        )

        if revenue:
            event.measurements['revenue'] = revenue

        self.collect_event(event)

    def _enrich_event(self, event: UnifiedEvent) -> UnifiedEvent:
        """Enrich event with contextual information"""
        # Add trace context if available
        if self.trace_context:
            trace_info = self.trace_context.get_current()
            if trace_info:
                event.trace_id = trace_info.get('trace_id')
                event.span_id = trace_info.get('span_id')
                event.parent_span_id = trace_info.get('parent_span_id')

        # Add user context if available
        if self.user_context:
            user_info = self.user_context.get_current()
            if user_info:
                event.user_id = user_info.get('user_id')
                event.session_id = user_info.get('session_id')
                event.user_segment = user_info.get('segment')

        # Add feature flag context
        if self.feature_flags and event.user_id:
            flags = self.feature_flags.get_flags_for_user(event.user_id)
            if flags:
                event.custom_dimensions.update({
                    f'feature_flag_{k}': str(v) for k, v in flags.items()
                })

        # Add system context
        import socket
        event.host_name = socket.gethostname()
        event.service_name = self.config.get('service_name', 'unknown')
        event.service_version = self.config.get('service_version', '1.0.0')
        event.environment = self.config.get('environment', 'production')

        return event

    def _should_sample(self, event: UnifiedEvent) -> bool:
        """Determine if event should be sampled"""
        # Get sampling rate for event type
        sampling_rate = self.sampling_rules.get(
            f"{event.domain}.{event.category}",
            self.sampling_rules.get('default', 1.0)
        )

        # Always sample errors and critical business events
        if (event.severity == 'error' or
            event.business_impact == 'critical'):
            return True

        import random
        return random.random() < sampling_rate

    def _passes_filters(self, event: UnifiedEvent) -> bool:
        """Check if event passes configured filters"""
        for filter_func in self.filters:
            try:
                if not filter_func(event):
                    return False
            except Exception as e:
                print(f"Error applying filter: {e}")

        return True

    def _process_events(self):
        """Background worker to process events"""
        batch = []
        last_flush = time.time()

        while self.running or not self.event_buffer.empty():
            try:
                # Get event with timeout
                event = self.event_buffer.get(timeout=1)
                batch.append(event)

                # Flush batch if full or timeout reached
                if (len(batch) >= self.config.get('batch_size', 100) or
                    time.time() - last_flush > self.config.get('flush_interval', 30)):

                    self._flush_batch(batch)
                    batch = []
                    last_flush = time.time()

            except queue.Empty:
                # Flush any remaining events
                if batch:
                    self._flush_batch(batch)
                    batch = []
                    last_flush = time.time()

    def _flush_batch(self, events: List[UnifiedEvent]):
        """Flush batch of events to configured exporters"""
        for exporter_name, exporter in self.exporters.items():
            try:
                exporter.export(events)
            except Exception as e:
                print(f"Error exporting to {exporter_name}: {e}")

    def _flush_remaining_events(self):
        """Flush any remaining events in buffer"""
        remaining_events = []
        while not self.event_buffer.empty():
            try:
                event = self.event_buffer.get_nowait()
                remaining_events.append(event)
            except queue.Empty:
                break

        if remaining_events:
            self._flush_batch(remaining_events)

    def _handle_buffer_overflow(self):
        """Handle buffer overflow by dropping oldest events"""
        try:
            # Remove oldest event to make room
            self.event_buffer.get_nowait()
        except queue.Empty:
            pass

# Example exporters
class ObservabilityExporter:
    """Export events to observability systems"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config

    def export(self, events: List[UnifiedEvent]):
        """Export events to observability platforms"""
        for event in events:
            if event.domain == "observability":
                # Send to monitoring systems (Prometheus, Grafana, etc.)
                self._send_to_monitoring(event.to_observability_format())

    def _send_to_monitoring(self, event_data: Dict[str, Any]):
        """Send to monitoring system"""
        # Implementation for specific monitoring platform
        pass

class TelemetryExporter:
    """Export events to telemetry systems"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config

    def export(self, events: List[UnifiedEvent]):
        """Export events to telemetry platforms"""
        for event in events:
            if event.domain == "telemetry":
                # Send to analytics systems
                self._send_to_analytics(event.to_telemetry_format())

    def _send_to_analytics(self, event_data: Dict[str, Any]):
        """Send to analytics system"""
        # Implementation for specific analytics platform
        pass

class UnifiedExporter:
    """Export events to unified data store"""

    def __init__(self, config: Dict[str, Any]):
        self.config = config

    def export(self, events: List[UnifiedEvent]):
        """Export all events to unified storage"""
        for event in events:
            # Send to data warehouse or data lake
            self._send_to_data_store(event.to_unified_format())

    def _send_to_data_store(self, event_data: Dict[str, Any]):
        """Send to unified data store"""
        # Implementation for data warehouse/lake
        pass

# Usage example
def setup_unified_collection():
    """Setup unified observability and telemetry collection"""
    config = {
        'service_name': 'user-service',
        'service_version': '1.2.3',
        'environment': 'production',
        'buffer_size': 10000,
        'batch_size': 100,
        'flush_interval': 30,
        'sampling_rules': {
            'observability.metric': 0.1,
            'observability.performance': 0.5,
            'observability.error': 1.0,
            'telemetry.user_interaction': 0.2,
            'telemetry.business_event': 1.0,
            'default': 0.1
        }
    }

    collector = UnifiedEventCollector(config)

    # Add exporters
    collector.exporters['observability'] = ObservabilityExporter(config)
    collector.exporters['telemetry'] = TelemetryExporter(config)
    collector.exporters['unified'] = UnifiedExporter(config)

    # Add filters
    def privacy_filter(event: UnifiedEvent) -> bool:
        """Filter out events with sensitive data"""
        sensitive_keys = ['password', 'ssn', 'credit_card']
        for key in sensitive_keys:
            if any(key in str(v).lower() for v in event.properties.values()):
                return False
        return True

    collector.filters.append(privacy_filter)

    collector.start()
    return collector
```

## Unified Analytics and Insights

### Cross-Domain Analysis Engine
```python
# Example: Analytics engine that combines observability and telemetry data
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
import matplotlib.pyplot as plt
import seaborn as sns

@dataclass
class UnifiedInsight:
    """Unified insight combining observability and telemetry data"""
    insight_type: str
    domain: str  # 'technical', 'business', 'user_experience'
    priority: str  # 'low', 'medium', 'high', 'critical'
    title: str
    description: str
    evidence: Dict[str, Any]
    recommendations: List[str]
    impact_score: float  # 0-100
    confidence: float  # 0-1

class UnifiedAnalyticsEngine:
    """Analytics engine for combined observability and telemetry analysis"""

    def __init__(self, data_source: str):
        self.data_source = data_source
        self.correlation_rules = []
        self.alert_thresholds = {}

    def load_unified_data(self, start_date: datetime, end_date: datetime,
                         domains: Optional[List[str]] = None) -> pd.DataFrame:
        """Load unified observability and telemetry data"""
        query = f"""
        SELECT *
        FROM unified_events
        WHERE timestamp BETWEEN '{start_date}' AND '{end_date}'
        """

        if domains:
            domain_list = "', '".join(domains)
            query += f" AND domain IN ('{domain_list}')"

        df = pd.read_sql(query, self.data_source)
        return df

    def analyze_user_experience_impact(self, df: pd.DataFrame) -> List[UnifiedInsight]:
        """Analyze how technical issues impact user experience"""
        insights = []

        # Correlate error rates with user interaction success
        error_data = df[
            (df['domain'] == 'observability') &
            (df['category'] == 'error')
        ].copy()

        user_data = df[
            (df['domain'] == 'telemetry') &
            (df['category'] == 'user_interaction')
        ].copy()

        if not error_data.empty and not user_data.empty:
            # Group by time windows
            error_data['timestamp'] = pd.to_datetime(error_data['timestamp'])
            user_data['timestamp'] = pd.to_datetime(user_data['timestamp'])

            # Resample to 5-minute windows
            error_rates = error_data.resample('5T', on='timestamp').size()
            user_success_rates = user_data.groupby(
                pd.Grouper(key='timestamp', freq='5T')
            )['properties'].apply(
                lambda x: sum(1 for props in x if props.get('outcome') == 'success') / len(x) * 100
            )

            # Calculate correlation
            correlation = error_rates.corr(user_success_rates)

            if abs(correlation) > 0.5:  # Strong correlation
                insights.append(UnifiedInsight(
                    insight_type='correlation',
                    domain='user_experience',
                    priority='high' if abs(correlation) > 0.7 else 'medium',
                    title='Technical Errors Impact User Experience',
                    description=f'Strong correlation ({correlation:.2f}) between system errors and user interaction failures',
                    evidence={
                        'correlation_coefficient': correlation,
                        'error_rate_avg': error_rates.mean(),
                        'user_success_rate_avg': user_success_rates.mean()
                    },
                    recommendations=[
                        'Implement proactive error monitoring',
                        'Set up alerts for error rate spikes',
                        'Improve error handling in user-facing features'
                    ],
                    impact_score=abs(correlation) * 100,
                    confidence=0.8
                ))

        return insights

    def analyze_performance_business_impact(self, df: pd.DataFrame) -> List[UnifiedInsight]:
        """Analyze how performance metrics impact business metrics"""
        insights = []

        # Get performance data
        perf_data = df[
            (df['domain'] == 'observability') &
            (df['category'] == 'performance')
        ].copy()

        # Get business event data
        business_data = df[
            (df['domain'] == 'telemetry') &
            (df['category'] == 'business_event')
        ].copy()

        if not perf_data.empty and not business_data.empty:
            # Analyze response time vs conversion rates
            perf_data['timestamp'] = pd.to_datetime(perf_data['timestamp'])
            business_data['timestamp'] = pd.to_datetime(business_data['timestamp'])

            # Calculate hourly metrics
            hourly_perf = perf_data.resample('1H', on='timestamp')['measurements'].apply(
                lambda x: np.mean([m.get('duration_ms', 0) for m in x if isinstance(m, dict)])
            )

            hourly_conversions = business_data[
                business_data['name'].str.contains('conversion', case=False, na=False)
            ].resample('1H', on='timestamp').size()

            if len(hourly_perf) > 10 and len(hourly_conversions) > 10:
                # Find periods of high response time
                high_perf_threshold = hourly_perf.quantile(0.8)
                high_perf_periods = hourly_perf > high_perf_threshold

                # Compare conversion rates
                normal_conversion_rate = hourly_conversions[~high_perf_periods].mean()
                high_perf_conversion_rate = hourly_conversions[high_perf_periods].mean()

                impact_ratio = (normal_conversion_rate - high_perf_conversion_rate) / normal_conversion_rate

                if impact_ratio > 0.1:  # 10% or more impact
                    insights.append(UnifiedInsight(
                        insight_type='performance_impact',
                        domain='business',
                        priority='critical' if impact_ratio > 0.3 else 'high',
                        title='Poor Performance Impacts Conversions',
                        description=f'High response times reduce conversions by {impact_ratio:.1%}',
                        evidence={
                            'performance_threshold': high_perf_threshold,
                            'normal_conversion_rate': normal_conversion_rate,
                            'degraded_conversion_rate': high_perf_conversion_rate,
                            'impact_ratio': impact_ratio
                        },
                        recommendations=[
                            'Optimize slow database queries',
                            'Implement caching for frequently accessed data',
                            'Set up performance monitoring alerts',
                            'Consider auto-scaling based on response times'
                        ],
                        impact_score=impact_ratio * 100,
                        confidence=0.75
                    ))

        return insights

    def analyze_feature_adoption_stability(self, df: pd.DataFrame) -> List[UnifiedInsight]:
        """Analyze relationship between feature stability and adoption"""
        insights = []

        # Get feature usage data
        feature_data = df[
            (df['domain'] == 'telemetry') &
            (df['category'] == 'user_interaction') &
            (df['feature_flag'].notna())
        ].copy()

        # Get error data by feature
        error_data = df[
            (df['domain'] == 'observability') &
            (df['severity'] == 'error') &
            (df['custom_dimensions'].apply(
                lambda x: any('feature_flag' in str(k) for k in x.keys()) if isinstance(x, dict) else False
            ))
        ].copy()

        if not feature_data.empty:
            # Analyze feature adoption trends
            feature_adoption = feature_data.groupby('feature_flag').agg({
                'user_id': 'nunique',
                'event_id': 'count',
                'timestamp': ['min', 'max']
            })

            feature_adoption.columns = ['unique_users', 'total_interactions', 'first_seen', 'last_seen']

            # Calculate adoption velocity
            for feature in feature_adoption.index:
                days_active = (feature_adoption.loc[feature, 'last_seen'] -
                             feature_adoption.loc[feature, 'first_seen']).days

                if days_active > 0:
                    adoption_velocity = feature_adoption.loc[feature, 'unique_users'] / days_active

                    # Check if adoption is declining
                    recent_data = feature_data[
                        (feature_data['feature_flag'] == feature) &
                        (feature_data['timestamp'] > datetime.now() - timedelta(days=7))
                    ]

                    older_data = feature_data[
                        (feature_data['feature_flag'] == feature) &
                        (feature_data['timestamp'] <= datetime.now() - timedelta(days=7)) &
                        (feature_data['timestamp'] > datetime.now() - timedelta(days=14))
                    ]

                    if not recent_data.empty and not older_data.empty:
                        recent_users = recent_data['user_id'].nunique()
                        older_users = older_data['user_id'].nunique()

                        adoption_change = (recent_users - older_users) / older_users

                        if adoption_change < -0.2:  # 20% decline
                            insights.append(UnifiedInsight(
                                insight_type='feature_decline',
                                domain='business',
                                priority='medium',
                                title=f'Feature {feature} Adoption Declining',
                                description=f'Feature adoption has declined by {abs(adoption_change):.1%} in the past week',
                                evidence={
                                    'feature_name': feature,
                                    'adoption_change': adoption_change,
                                    'recent_users': recent_users,
                                    'previous_users': older_users,
                                    'total_users': feature_adoption.loc[feature, 'unique_users']
                                },
                                recommendations=[
                                    'Investigate feature stability issues',
                                    'Collect user feedback on feature experience',
                                    'Review recent feature changes',
                                    'Consider A/B testing improvements'
                                ],
                                impact_score=abs(adoption_change) * 50,
                                confidence=0.7
                            ))

        return insights

    def generate_unified_insights_report(self, start_date: datetime,
                                       end_date: datetime) -> Dict[str, Any]:
        """Generate comprehensive insights report combining all domains"""
        df = self.load_unified_data(start_date, end_date)

        if df.empty:
            return {'error': 'No data found for specified period'}

        all_insights = []

        # Run all analysis functions
        all_insights.extend(self.analyze_user_experience_impact(df))
        all_insights.extend(self.analyze_performance_business_impact(df))
        all_insights.extend(self.analyze_feature_adoption_stability(df))

        # Sort insights by priority and impact
        priority_order = {'critical': 4, 'high': 3, 'medium': 2, 'low': 1}
        all_insights.sort(
            key=lambda x: (priority_order.get(x.priority, 0), x.impact_score),
            reverse=True
        )

        # Generate summary statistics
        summary = {
            'total_events': len(df),
            'event_breakdown': df['domain'].value_counts().to_dict(),
            'category_breakdown': df['category'].value_counts().to_dict(),
            'unique_users': df['user_id'].nunique(),
            'unique_services': df['service_name'].nunique(),
            'time_range': {
                'start': start_date.isoformat(),
                'end': end_date.isoformat()
            }
        }

        # Create executive summary
        executive_summary = self._create_executive_summary(all_insights, summary)

        return {
            'summary': summary,
            'executive_summary': executive_summary,
            'insights': [
                {
                    'type': insight.insight_type,
                    'domain': insight.domain,
                    'priority': insight.priority,
                    'title': insight.title,
                    'description': insight.description,
                    'evidence': insight.evidence,
                    'recommendations': insight.recommendations,
                    'impact_score': insight.impact_score,
                    'confidence': insight.confidence
                }
                for insight in all_insights
            ],
            'insights_by_priority': {
                priority: len([i for i in all_insights if i.priority == priority])
                for priority in ['critical', 'high', 'medium', 'low']
            }
        }

    def _create_executive_summary(self, insights: List[UnifiedInsight],
                                 summary: Dict[str, Any]) -> str:
        """Create executive summary of insights"""
        critical_insights = [i for i in insights if i.priority == 'critical']
        high_insights = [i for i in insights if i.priority == 'high']

        summary_text = f"Analysis of {summary['total_events']:,} events revealed {len(insights)} key insights. "

        if critical_insights:
            summary_text += f"{len(critical_insights)} critical issues require immediate attention, "

        if high_insights:
            summary_text += f"{len(high_insights)} high-priority items need addressing. "

        # Highlight top insight
        if insights:
            top_insight = insights[0]
            summary_text += f"Primary concern: {top_insight.title} (Impact: {top_insight.impact_score:.0f}/100)."

        return summary_text

# Usage example
def run_unified_analysis():
    """Run unified observability and telemetry analysis"""
    analytics = UnifiedAnalyticsEngine("your_unified_data_source")

    end_date = datetime.utcnow()
    start_date = end_date - timedelta(days=7)

    report = analytics.generate_unified_insights_report(start_date, end_date)

    # Print executive summary
    print("Executive Summary:")
    print(report['executive_summary'])
    print("\nTop Insights:")

    for insight in report['insights'][:5]:
        print(f"- [{insight['priority'].upper()}] {insight['title']}")
        print(f"  Impact: {insight['impact_score']:.0f}/100")
        print()

    return report
```

## Best Practices for Unified Observability and Telemetry

### Integration Principles
✅ Use common correlation identifiers across all data types
✅ Implement unified event schemas with domain-specific extensions
✅ Design for cross-domain analysis and insights
✅ Maintain separate pipelines but unified analysis
✅ Use sampling strategies that preserve correlations
✅ Implement consistent privacy and security controls
✅ Enable real-time correlation between operational and business metrics
✅ Design dashboards that combine both perspectives

### Anti-Patterns to Avoid
❌ Mixing operational and business data without clear boundaries
❌ Using different correlation schemes for different data types
❌ Over-instrumenting without considering the combined data volume
❌ Analyzing domains in isolation without cross-correlation
❌ Implementing different privacy controls for similar data
❌ Creating separate teams without collaboration mechanisms
❌ Not considering the performance impact of unified collection
❌ Ignoring the cost implications of storing all data types

### Implementation Strategy
1. **Start with Correlation**: Implement common identifiers first
2. **Unified Schema**: Design extensible event schemas
3. **Separate Collection**: Maintain domain-specific collection logic
4. **Unified Storage**: Store in common format for analysis
5. **Cross-Domain Analysis**: Build analytics that span domains
6. **Iterative Improvement**: Continuously refine based on insights
